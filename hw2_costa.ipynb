{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2aab6315785a55821fd462327dd36765",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img src='https://hammondm.github.io/hltlogo1.png' style=\"float:right\">\n",
    "Linguistics 531<br>\n",
    "Fall 2024<br>\n",
    "Jackson\n",
    "\n",
    "## Things to remember about any homework assignment:\n",
    "\n",
    "1. For this assignment, you will edit this jupyter notebook and turn it in. Do not turn in pdf files or separate `.py` files.\n",
    "1. Late work is not accepted.\n",
    "1. Given the way I grade, you should try to answer *every* question, even if you don't like your answer or have to guess.\n",
    "1. You may *not* use `python` modules that we have not already used in class. (For grading, it needs to be able to run on my machine, and the way to do that is to limit yourself to the modules we've discussed and that are loaded into the Notebook.)\n",
    "1. Don't use editors *other* than Jupyter Notebook to work on and submit your assignment, since they will mangle the autograding features: Google Colab, or even just editing the `.ipynb` file as a plain text file. Diagnosing and fixing that kind of problem takes a lot of my time, and that means less of my time to offer constructive feedback to you and to other students.\n",
    "1. You may certainly talk to your classmates about the assignment, but everybody must turn in *their own* work. It is not acceptable to turn in work that is essentially the same as the work of classmates, or the work of someone on Stack Overflow, or the work of a generative AI model. Using someone else's code and simply changing variable or object names is *not* doing your own work.\n",
    "1. All code must run. It doesn't have to be perfect, it may not do all that you want it to do, but it must run without error. Code that runs with errors will get no credit from the autograder.\n",
    "1. Code must run in reasonable time. Assume that if it takes more than *5 minutes* to run (on your machine), that's too long.\n",
    "1. Make sure to select `restart, run all cells` from the `kernel` menu when you're done and before you turn this in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my name: Kathleen Costa\n",
    "\n",
    "people I talked to about the assignment: N/A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2ad045043fa401a2303b5fc38127c6d7",
     "grade": false,
     "grade_id": "hw2header",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Homework #2\n",
    "\n",
    "**This is due Tuesday, October 29, 2024 at noon (Arizona time).**\n",
    "\n",
    "This assignment continues with the `NewB` corpus (downloadable [here](https://github.com/JerryWei03/NewB)).\n",
    "\n",
    "We first build an incidence-based term index from the `train_orig.txt` file. Remember that we are treating **each sentence as a separate document when building our index**. We are not treating each publication *source*, as indicated by the integer on each line, as a document; instead, that source number will be metadata. We'll make use of that later, when we look at classification of documents.\n",
    "\n",
    "You may adapt any of the code from class for this or use your own, but bear in mind the that aspects of the code from class notebooks are tailored to the *different* file and data structure of the Blogger corpus. You may also use or adapt code from your first assignment. Do *not* stem or remove stop words.\n",
    "\n",
    "Imports and important constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You may use the RE module, if you choose, to perform the text normalization that is required here.\n",
    "# There may be ways to accomplish what you need to do using the Python standard library, so you're\n",
    "#  not required to use RE--but it's available if you choose.\n",
    "import re\n",
    "\n",
    "# You may also use a Counter() for this and future assignments, though you are not required to do so.\n",
    "#  To learn more about Counter() objects, see https://realpython.com/python-counter/\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "71527eb8cec0399079098c32aacfbfa0",
     "grade": false,
     "grade_id": "cell-85e7bb5f0c446cb1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**As with HW 1, make my autograding life easier (and your own notebook more likely to be graded correctly):**\n",
    "\n",
    "In order for me to develop this assignment, and in order for me to **grade** your submission for this assignment, I need to be working with the right file that we load our corpus from. On my machine, that file has this path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "28497011f8bd6b55ec508bc5635b041a",
     "grade": false,
     "grade_id": "cell-b7e8e00e5c53b643",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Path on my own machine, needed for GRADING\n",
    "newbfile = '/home/ejackson1/Downloads/linguistics/NewB/train_orig.txt'\n",
    "\n",
    "# ie, DON'T CHANGE THIS CELL, CHANGE THE ONE BELOW!\n",
    "#  If you change *this* cell, the autograding is likely to break."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "555072d0e133a10b43330329f1af0f3b",
     "grade": false,
     "grade_id": "cell-26968d9281db051c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "However, for **you** to work on your own code, you need to point this notebook to the path for this file on your own machine. *You should enter the path on your own machine in the editable code cell below,* then uncomment that line so the notebook works on your machine. This means that the second code cell will take precedence in assigning the value of the path to the corpus, and you can write your code to open that file without problems.\n",
    "\n",
    "**HOWEVER, BEFORE YOU SUBMIT to D2L** comment out **your** path again. This means that when I run the code on my own machine, it'll have the path that ***I*** need, and it'll grade your notebook properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR path\n",
    "newbfile = '/hlt2/train_orig.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1a83f21aec609ab2e161f91e07728846",
     "grade": false,
     "grade_id": "q1q",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**1.** Flesh out the two functions below. One function extracts each sentence from the document and parses off the integer that represents the publication source. For each sentence, we create an \"incidence list\" which is the set of words in that document (as described in the docstring below). (6 points total)\n",
    "\n",
    "The data in the NewB corpus has supposedly already been normalized; things like apostrophes and punctuation have mostly been removed, and all text should have been made lower case. Percent signs have been left on numbers that represent percent. However, it looks like there may be some issues with the normalization method, since some characters besides just lower-case ASCII remain in the document. These include left and right curly braces { }, some back-ticks \\`, and even stranger things. So, in order for us all to be working on the same data and getting the same answers, you're going to also create a normalization and tokenization function that will institute a standard method of preprocessing our text:\n",
    "\n",
    "Follow the docstring for the second function below, and pay special attention to the data types. This function should replace all characters in the sentence that are not letters (upper or lower case ASCII letters), digits, or the percent sign % by a space. We'll then define \"words\" (which will be the *terms* for our index) to be any remaining alphanumeric characters which are found between spaces. For this assignment, do *not* normalize in any other way or stem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa435cca8bf44a3face4a4bf12caa7c2",
     "grade": false,
     "grade_id": "q1a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def makeDocuments(filename):\n",
    "    '''reads in the source file and returns a structured list\n",
    "         of documents, with text normalization as described in\n",
    "         the normalize_tokenize() function below.\n",
    "    \n",
    "    args:\n",
    "        filename: location of train_orig.txt\n",
    "    returns:\n",
    "        documents: a list of triples:\n",
    "            document source ID (as an integer)\n",
    "            document text (normalized but not split, as a string)\n",
    "            *set* of words in this document (normalized, as a set)\n",
    "\n",
    "       Document IDs within our collection are assumed to be the\n",
    "         integer index at which that document occurs in this list,\n",
    "         which should also match the line number in the original\n",
    "         document.\n",
    "'''\n",
    "    # YOUR CODE HERE   \n",
    "    documents = []\n",
    "    \n",
    "    with open(filename, 'r') as file:\n",
    "        for line_num, line in enumerate(file):\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                match = re.match(r'^(\\d+)\\s*(.*)', line)\n",
    "                if match:\n",
    "                    source_id = int(match.group(1))  \n",
    "                    sentence = match.group(2)  \n",
    "                \n",
    "                    normalized_text, words_set = normalize_tokenize(sentence)\n",
    "                   \n",
    "                    documents.append((source_id, normalized_text, words_set))\n",
    "    \n",
    "    return documents\n",
    "def normalize_tokenize(sentence):\n",
    "    '''Takes as input a line of text (assumed to be a multi-word sentence) and\n",
    "    returns that sentence, normalized and tokenized into words.\n",
    "    \n",
    "    Conventions:\n",
    "    -- upper and lower case ASCII letters (a-z and A-Z, with no diacritics) are kept\n",
    "    -- digits (0-9) are kept\n",
    "    -- percent sign (%) is kept\n",
    "    All other characters are converted to whitespace, and words (terms) are\n",
    "         then split on whitespace.\n",
    "    \n",
    "    args:\n",
    "        sentence: a sentence from the corpus, as a string\n",
    "    returns:\n",
    "        normalized: a normalized version of the sentence, as described in the\n",
    "            conventions above\n",
    "        tokenized: the sequence of normalized words from the sentence, split\n",
    "            on whitespace, as a list\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    normalized = re.sub(r'[^a-zA-Z0-9%]', ' ', sentence)\n",
    "    normalized = normalized.strip()\n",
    "    tokenized = set(normalized.split())\n",
    "    \n",
    "    return normalized, tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "292585a49c6ffb055ea5c90b59eca13e",
     "grade": false,
     "grade_id": "cell-1fb609f870acc9a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Before working on `makeDocuments()`, make sure your tokenization function works!\n",
    "\n",
    "Your `makeDocuments()` function won't be able to pass its tests if your `normalize_tokenize()` function isn't doing what it needs to do. So, let's test that tokenization function first!\n",
    "\n",
    "We'll be testing (for points!) the document at index 4171. In the original file, that line looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e5bf855e10f2d71cd8d45a1a702f6a3",
     "grade": false,
     "grade_id": "cell-944fa043f8e67682",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_sentence = 'hes the son of a physician from lawrence� he graduated from cooley�law school�worked for�his uncle the dentist who owned the el caribe catering hall in brooklyn dealt�in taxi medallions used to live in trump tower sought a city council seat and�paid money from trump�to former porn star stormy daniels'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6fc5f47e604dc4b48292439337b96066",
     "grade": false,
     "grade_id": "cell-77efc8bf850d1070",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the original file, this would have ended with a newline, but I'm assuming that you'll strip newlines in the part of your code that reads in the file, just like you did in HW1. So, your `normalize_tokenize()` function will be operating on it *after* the newline has been removed.\n",
    "\n",
    "I'm not sure where these non-ASCII characters came from, since they don't appear to be in the original article, which seems to be this one:\n",
    "\n",
    "https://web.archive.org/web/20220521092314/https://www.newsday.com/long-island/donald-trump-michael-cohen-w71594\n",
    "\n",
    "Your `normalize_tokenize()` function ought to reformat this document like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd7d6fe52d2c35beeb6503f703722b3a",
     "grade": false,
     "grade_id": "cell-88efa8f72a43fbe9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "normalized = 'hes the son of a physician from lawrence  he graduated from cooley law school worked for his uncle the dentist who owned the el caribe catering hall in brooklyn dealt in taxi medallions used to live in trump tower sought a city council seat and paid money from trump to former porn star stormy daniels'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d9b0dc202e637e056f2e106ab1088afb",
     "grade": false,
     "grade_id": "cell-9d9d70248ff07073",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Note that the characters that are NOT upper case ASCII A-Z, lower case ASCII a-z, digits 0-9, or the percent sign % are simply converted to a single space. In a few places, this results in a sequence of two or more spaces. We don't want to \"find\" a zero-length string in between two spaces, so be careful how you tokenize this with Python's `str.split()`!\n",
    "\n",
    "Your function should tokenize it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a8a7ff27803c14c6afae4fdf5a9c7db",
     "grade": false,
     "grade_id": "cell-464b3b91a4c2d440",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tokenized = ['hes', 'the', 'son', 'of', 'a', 'physician', 'from', 'lawrence', 'he',\n",
    "             'graduated', 'from', 'cooley', 'law', 'school', 'worked', 'for', 'his',\n",
    "             'uncle', 'the', 'dentist', 'who', 'owned', 'the', 'el', 'caribe', 'catering',\n",
    "             'hall', 'in', 'brooklyn', 'dealt', 'in', 'taxi', 'medallions', 'used',\n",
    "             'to', 'live', 'in', 'trump', 'tower', 'sought', 'a', 'city', 'council',\n",
    "             'seat', 'and', 'paid', 'money', 'from', 'trump', 'to', 'former', 'porn',\n",
    "             'star', 'stormy', 'daniels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "abcd1912545128e025a0bd87f9362e6b",
     "grade": false,
     "grade_id": "cell-92fa60bb204c72e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Before the tests that count for points (below), here's a test just to make sure that this function is working properly. In LING 508, you'll learn about \"Test-Driven Development,\" but here's a chance to start working in this way. WRITE YOUR FUNCTION SO THAT IT WILL PASS THIS TEST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba49e69fb7390a7e1c4b3e8da0ba9497",
     "grade": false,
     "grade_id": "cell-3c4f46a03d5cf529",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hooray--your normalize_tokenize() function works as it should!\n"
     ]
    }
   ],
   "source": [
    "if (normalized, tokenized == normalize_tokenize(test_sentence)):\n",
    "    print(\"Hooray--your normalize_tokenize() function works as it should!\")\n",
    "else:\n",
    "    print(\"Hmm, keep trying!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ff32fe37e4db3d08b3dcfb62518c3252",
     "grade": false,
     "grade_id": "cell-90142d649ed5585e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Now you can move on to the `makeDocuments()` function, and make sure it's working properly, as well&mdash;this time for points!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6850e9dedee6acc3db575aee13abd791",
     "grade": true,
     "grade_id": "q1t1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 1a, 1 pt\n",
    "docs = makeDocuments(newbfile)\n",
    "assert len(docs) == 253781"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e6c90da48fd0bb920aeb3e29b63a964",
     "grade": true,
     "grade_id": "q1t2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 1b, 1 pt\n",
    "assert type(docs[10]) == tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "053efbe92f504fe4cfa0abaa24dd9df0",
     "grade": true,
     "grade_id": "q1t3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 1c, 1 pt\n",
    "assert len(docs[10]) == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "509130aa980826a70f3eb5c2e64816b5",
     "grade": true,
     "grade_id": "q1t4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 1d, 1 pt\n",
    "assert docs[4171][0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f23ce893c7b040a138ec855c1b51fb14",
     "grade": true,
     "grade_id": "q1t5",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 1e, 1 pt\n",
    "#   This is really a test of your normalize_tokenize() function, and\n",
    "#   how you've integrated it into the makeDocuments() function.\n",
    "assert docs[4171][1] == 'hes the son of a physician from lawrence  he graduated from cooley law school worked for his uncle the dentist who owned the el caribe catering hall in brooklyn dealt in taxi medallions used to live in trump tower sought a city council seat and paid money from trump to former porn star stormy daniels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2262e5f5cd183229fa943af7b3e210f0",
     "grade": true,
     "grade_id": "q1t6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 1f, 1 pt\n",
    "#   This is ALSO testing the output of your normalize_tokenize() function!\n",
    "assert len(docs[4171][2]) == 46"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dfeeaef199d982e7a57dc88bfa057d8d",
     "grade": false,
     "grade_id": "q2q",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**2.** The following function takes the output of `makeDocuments()` and creates an incidence-based index. We represent the index as a dictionary that maps from words to a *sorted* list of integer document IDs. The integer document IDs are the indices at which that document occurs in the structured list of documents that is returned by `makeDocuments()`. (4 points total)\n",
    "\n",
    "(Note that there is the potential for confusion here, since the word _index_ is being used two ways to refer to two different things. First, the incidence-based _index_ that we're building refers to a dictionary that maps from terms to a list of the document IDs that they occur in. Second, the integer document IDs are an _index_, that is, an integer that allows us to specify an item in our document list, like a subscript or a counter.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91d9e4e5ac571cdb1286e181c4de1d4e",
     "grade": false,
     "grade_id": "q2a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def makeIndex(documents):\n",
    "    '''maps from a documents list to an\n",
    "    incidence index represented as a dictionary\n",
    "    from words to sorted lists of document IDs\n",
    "    \n",
    "    args:\n",
    "        documents: a documents list as produced\n",
    "            by makeDocuments()\n",
    "    returns:\n",
    "        index: a dictionary from words to lists\n",
    "            of document IDs (ie, indices in the\n",
    "            documents list)\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    index = {}\n",
    "    for doc_id, (_, _, word_set) in enumerate(documents):\n",
    "        for word in word_set:\n",
    "            index.setdefault(word, []).append(doc_id)\n",
    "    \n",
    "    for word_list in index.values():\n",
    "        word_list.sort()\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1876082bad01e7b0941ec936127fefba",
     "grade": true,
     "grade_id": "q2t1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "docs = makeDocuments(newbfile)\n",
    "idx = makeIndex(docs)\n",
    "\n",
    "# test 2a, 1 pt\n",
    "assert type(idx) == dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3d2f866794e8c4134dd56b1f3c9aeff4",
     "grade": true,
     "grade_id": "q2t2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 2b, 1 pt\n",
    "assert len(idx) == 61193"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c77231b38409cb9afaf597950e79faf1",
     "grade": true,
     "grade_id": "q2t3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 2c, 1 pt\n",
    "assert idx['champagnes'] == [223755]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "75a394574a92a5545acd32d13f03b519",
     "grade": true,
     "grade_id": "q2t4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 2d, 1 pt\n",
    "assert idx['happiness'] == [16495,66139,84943,\n",
    "                            85998,91589,93472,\n",
    "                            120070,133078,193349]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "59fe813c125fa302324beb7095aead5a",
     "grade": false,
     "grade_id": "q3q",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**3.** Now write a function that will return the set of all document IDs that contain some set of words. (5 points total)\n",
    "\n",
    "The function should take two arguments:\n",
    "\n",
    "- an index (ie, the output of `makeIndex`)\n",
    "- a list of strings (ie, the search query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be7b37a05ba5492b3e29301dd26e3476",
     "grade": false,
     "grade_id": "q3a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def search(idx,ws):\n",
    "    '''returns the set of documents that contain\n",
    "    some set of words\n",
    "    \n",
    "    args:\n",
    "        idx: an incidence index, as created by\n",
    "            makeIndex()\n",
    "        ws: a list of words\n",
    "    returns:\n",
    "        docs: a set of document indices\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    if not ws:\n",
    "        return set()\n",
    "        \n",
    "    results = set(idx.get(ws[0], set()))\n",
    "    \n",
    "    for term in ws[1:]:\n",
    "        if term not in idx:\n",
    "            return set()\n",
    "        results &= set(idx[term])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bc70a5ece0ef6a070125ce531a42e8a7",
     "grade": true,
     "grade_id": "q3t1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "docs = makeDocuments(newbfile)\n",
    "idx = makeIndex(docs)\n",
    "\n",
    "# test 3a, 1 pt\n",
    "assert type(search(idx,['airplane'])) == set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "868c88a540165600587cf3cc955f8fcb",
     "grade": true,
     "grade_id": "q3t2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 3b, 1 pt\n",
    "assert len(search(idx,['omelet'])) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fb738cbef757e2874b5d4b858b574f30",
     "grade": true,
     "grade_id": "q3t3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 3c, 1 pt\n",
    "assert search(idx,['senate','reject']) == {68347, 144901, 177620, 181422, 181564}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba82e48abf6d84cdb3e45cac785f2664",
     "grade": true,
     "grade_id": "q3t4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 3d, 1 pt\n",
    "assert search(idx,['wow','congress','airplane']) == set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9d9a3700c2c11f9e3d1460b83776dfe3",
     "grade": true,
     "grade_id": "q3t5",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 3e, 1 pt\n",
    "assert search(idx,['fire','wall']) == {32718, 46406, 49273, 67060, 154764, 178112, 201064}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "97fb550acb6ec75309ac799c74331764",
     "grade": false,
     "grade_id": "q4q",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**4.** Tweak the function so that it will complement any of the words. (5 points total)\n",
    "\n",
    "For example, if we call the function like this:\n",
    "\n",
    "```python\n",
    "dsearch(idx,['hat','*chair','coat'])\n",
    "```\n",
    "\n",
    "That will return all document IDs (indices) that contain *hat* and *coat*, but not *chair*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e6775702299ecca7880b4dcc84dae7b0",
     "grade": false,
     "grade_id": "q4a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def dsearch(idx,ws):\n",
    "    '''returns the set of documents that contain\n",
    "    or do *not* contain some set of words\n",
    "    \n",
    "    args:\n",
    "        idx: a term index as created by makeIndex()\n",
    "        ws: a list of words any of which may be\n",
    "            marked with a prefixed '*', which\n",
    "            indicates complement/negation\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    all_docs = set()\n",
    "    for docs in idx.values():\n",
    "        all_docs.update(docs)\n",
    "    \n",
    "    results = all_docs.copy()\n",
    "    \n",
    "    for term in ws:\n",
    "        if term.startswith('*'):\n",
    "            word = term[1:]\n",
    "            if word in idx:\n",
    "                results &= (all_docs - set(idx[word]))\n",
    "        else:\n",
    "            if term in idx:\n",
    "                results &= set(idx[term])\n",
    "            else:\n",
    "                return set()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62f62baed30316fa92fe90bc2b58bf08",
     "grade": true,
     "grade_id": "q4t1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "docs = makeDocuments(newbfile)\n",
    "idx = makeIndex(docs)\n",
    "\n",
    "# test 4a, 1 pt\n",
    "assert type(dsearch(idx,['airplane'])) == set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e9dfb9975bed22fa76e58045959ec72",
     "grade": true,
     "grade_id": "q4t2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 4b, 1 pt\n",
    "assert len(dsearch(idx,['hats','*other'])) == 85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f3affc6bfa5643fe5fdd7a1fea0be62a",
     "grade": true,
     "grade_id": "q4t3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 4c, 1 pt\n",
    "assert len(dsearch(idx,['hats'])) + \\\n",
    "len(dsearch(idx,['*hats'])) == \\\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9fbefe2bf8f7db88ad74fe785ec5e13e",
     "grade": true,
     "grade_id": "q4t4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 4d, 1 pt\n",
    "assert dsearch(idx,['win','send','*not']) == {57751, 251520}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e38bb5c9a5e50e7a0241642a97ba6803",
     "grade": true,
     "grade_id": "q4t5",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test 4e, 1 pt\n",
    "assert dsearch(idx,['win','*not']) == dsearch(idx,['*not','win'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9a5642a2004c525042a16b366d042579",
     "grade": false,
     "grade_id": "q5q",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**5.** How would you extend your function to include disjunction? In other words, think about what it would take to adapt this function so that you can have an OR connective as well as an AND connective. What aspects of this function will need to change? (3 points, manually graded)\n",
    "\n",
    "This has two parts. First, what would the syntax of the keywords need to be, that you would be passing as arguments to this function? How does the introduction of this new Boolean operation complicate the interpretation of a query?\n",
    "\n",
    "Second, how would you actually implement disjunction in the Python code? What is the built-in function that would be needed to represent it? *(Hint: Think about which operation we used to implement a Boolean AND. What's the operation that would correspond to Boolean OR?)*\n",
    "\n",
    "*For full points, your answer should make it clear that you understand how to represent the Boolean connectors in the search string in terms of set operations over the index. Your answer should also make it clear how the simple syntax that we've been using so far would become more complicated once we introduce the possibility of **disjunction** of search terms in addition to **conjunction** of search terms.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ce8c30972f3f04e6dd70c587c6406518",
     "grade": true,
     "grade_id": "q5a",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "To extend the dsearchfunction to include disjunction, I can use an OR and AND connective. For example, if I wanted to look for the words \"champagnes\" AND \"airplane\" OR \"happiness\" AND \"hats,\" I can change the syntax in the function to something like this: dsearch(idx, ['champagnes', 'airplane' | 'happiness', 'hats']). This would search for \"chapagnes\" AND either \"airplane\" OR (|) \"happiness\" AND includes the word \"hats.\" Introducing the OR connective with make the function more complex because the function will now expand the search to include documents that include either word, aside from just the AND connective which would use an intersecting logic. Having both of those functions in the code would make it more complex as it would have to identify multiple variations across several documents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
